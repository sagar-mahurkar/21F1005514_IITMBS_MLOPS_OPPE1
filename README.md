# Stock Analytica 
## Description 
- NSE minute-level data for stocks. 
- Data comprises opening price, highest price, closing price, traded volume for a stock at every minute in the period from 2018 to 2021.
- Prioritise Building the MLOps pipeline, don‚Äôt spend much time in modelling efficiency

## Instructions
for the first iteration of the model (v0), use data in StockAnalyticaData/v0 data folder comprising of these stocks:
- AARTIIND
- ABCAPITAL

For the second iteration of the model (v1), add StockAnalyticaData/v1 data to StockAnalyticaData/v0 -  the data from v1 data folder comprising of these stocks:
- ABFRL
- ADANIENT
- ADANIGAS

- refer to [data_processing_reference.ipynb](./data_processing_reference.ipynb)




---
---


# Submission Expectations

### **1. Private Git Repository URL ( [üîó Tutorial](https://youtu.be/w2y3LUfUhGk))** 
- Repository name format:  
  `<ROLLNUMBER_IN_CAPITAL_CASE>_IITMBS_MLOPS_OPPE1`
- Grant collaborator access to:  
  - [IITMBSMLOps](https://github.com/IITMBSMLOps) or  
  - `da5014_1@study.iitm.ac.in`
- Commit **all required files** directly to the Git repo - **(No separate ZIP file submission)**
- Commit history will be scrutinized  
  - Commit and push to remote **after every successful integration** with clear comments/commit messages
- ‚úÖ Repository must contain: 
  - Code/scripts used to complete the objective (`*.py`, `*.ipynb`, `*.sh`, etc.)
  - Output files (if any) showing successful completion
  - `README.md` explaining the purpose of each file
  - Standard dataset splits used for training
  - Any binary artifacts (pickle files, trained models, etc.)
- ‚ùå Should not contain:
    -   Video Screencast


### **2. Video Screencast**
‚úÖ Must cover the following:
- Explanation of the **problem statement**
- Approach to reach the objective
- Demonstration of cloud compute setup configuration
- Explanation of input files/data
- Demonstration of sequence of actions performed  
  - Examples of Actions:
  - Creating a Virtual Machine
  - SSH into VM
  - Running scripts
- Detailed explanation of scripts/code and objectives
- Errors encountered & how you resolved them
- Working demonstration in **GCP environment**
- Explanation of output files/data

### **3. AI Tool Usage Document - [üîóReference Document](https://docs.google.com/document/d/1EvwAigmLbvRDjgpgC19YFTrLCf25OnDzdcdI-2WNNNQ/edit?usp=drive_link)**
Should contain:
- AI tools used
- Prompts used
- Link(s) to shared chat(s)
- This can also be included in the Git repo as:  `AI_USAGE_DOC.md` 


# Examination Instructions
- Usage of AI tools is permitted
- Do **not** discuss anything with your peers.
- Plagiarism if found, will be dealt with severe consequences according to IIT-Madras Student Conduct
- Please submit within allotted time even if the pipeline is incomplete - partial marks are awarded appropriately
- Students are instructed to start the screencast recording only after the completion of whole pipeline or when they are done with their attempts in case of partial completion
- Students are expected to take permission from the proctor about the screencast recording - helps proctor not to flag the instance as malpractice 
- Students are expected to inform proctor after successful google form submission
- Students are expected to leave the meet only after completion of scheduled examination time slot - in case of early submissions
- Proctors do note the time of initiating video screencast creation, form submission for operational co-ordination based on student interaction
- In case of no acknowledgement from proctor, please message in Google Meet Chat ( Starting the Screencast Recording or Submission Successful)